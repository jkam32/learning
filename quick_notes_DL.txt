Chap 1 Intro
------------
- Keras (backend using Theano / Tensorflow); by Francois Chollet
- mxnet (distributed; multi-machine learning)
- OpenCV
- scikit-image
- scikit-learn
- expected outcome of the book
	- load image
	- preprocess image (for training a CNN)
	- build own implementation of CNN
	- implement popular CNN architecture (AlexNet, VGGNet, GoogLeNet, ResNet, SqueezeNet)
	- etc

Chap 2 What is Deep Learning?
-----------------------------
- DL \subset ML \subset AI
	- AI: automatic machine reasoning
	- ML: pattern recognition and learning from data
		- Artificial Neural Network (ANN) is one algorithm that specializes in pattern recognition / data learning
	
- History of NN and DL
	- 1943 			- first NN by McCulloch and Pitts - binary classifer with manual tuning of weights on inputs 
	- 1950s 		- Perceptron algorithm by Rosenblatt - automatic learning of weights - the automatic procedure is a basis of Stochastic Gradient Descent (SGD)
	- 1969 			- publication by Minky and Papert - showed that Perceptron with a linear activation (regardless of depths) cannot solve a non-linear problem;
					- XOR dataset as an example (a non-linear problem); impossible to draw a straight line that separates the two types of objects
					- almost killed the research on NN
	- 1970s - 1980s - Werbos + Rumelhart + LeCun - backpropagation algorithm - enables the training of multi-layered feedforward NN
					- TODO: Draw an example of multi-layered feedforward NN
					- combined with non-linear activation functions can solve the XOR problem
					- the backprop algorithm allows the NN to learn from the mistakes
					- slow technology + lack of labelled training datasets cause NN computation of more than 2 hidden layers infeasible
					- technology advancement has made training of multiple hidden layers feasible
						- aka Deep Learning
						- multiple hidden layers enable hierachical learning
							- base layer learns simple concepts
							- higher layers learn the abstractions
						- prime example 
							- Convolutional Neural Network (CNN) by LeCun in recognizing hand-written digits
							- learns discrimating patterns (filters) by stacking layers on top of each other
							- base layers learns edges and cornes
							- higher layers build on top of base layers for discrimation of different digits

- Hierachical Feature Learning
	- ML algorithms fall under - (I) supervised (II) unsupervised (III) semi-supervised
	- ML and image classification  - identify patterns used to differentiate different images
	- Historically, hand-engineered features are used to quantify the contents of an image (i.e. raw pixels are not fed into the algorithm, 
		and feature extractions are first performed)
		- feature extractions are some black-box algorithms that output a vector of information that seeks to quantify the images
			- notable examples
				- Histogram of Oriented Gradient(HOG) + Linear SVM - detect objects where viewpoint angle of images did not vary much from trained images

	- Instead of hand-defining the processes, DL (or CNN) learns the features automatically.  

- How "Deep" is deep?
	- > 2 layers of NN
	- DL is always associated with "more data leads to higher accuracy" (compared to traidional ML techniques which accuracy pleateaus with the increase of available data points

Chap 3: Image Fundamentals
--------------------------

- Pixels
	- building blocks of every image
	- can be represented on 
		- grayscale - [0, 255]
		- color using RGB scale, where each color space is on a scale of [0, 255]
			- RGB is an example of an additive color space (the more you add of each color, it tends towards bright colors)
	- denoted in the unit of x pixels wide, y pixels tall for a dimension of (x, y)
	- we always preprocess the image via mean substraction or scaling
	- the origin always starts at the top left, instead of the conventional bottom left
	- when accessing the coordinate of a pixel, probably easier to think in terms of row first (in terms of y) then followed by column (in terms of x)
	- in openCV, watch out that the color is stored in the reverse order of BGR (rather than RGB) due to historial reasons
	- scaling and aspect ratios
		- aspect ratio := width / height
		- scaling without maintaining the aspect ratios can always to lead to distortion of images
		- image classification algorithms always assume fixed-size input (in the form of (z X z, where z = 32, 64, 224, 227, 256, 299 among popular choices))
		- options include ignoring ratios and resize, resize along shortest dimension & center crop etc
		- no best method of scaling/ resizing

Chap 4: Image Classification Basics
-----------------------------------

- What is image classification?
	- Let there be an image I of W x H x 3 = N pixel, where W = width, H = height and 3 = depth of the color space (RGB in this case), and let there be categories of {A, B, C}. Image classification involves taking the image I and outputs a label 'A', 'B' or 'C' or a vector of probabilities associated with the probability of I belonging to 'A', 'B' or 'C'.
	- NB that our dataset consists of a collection of data points (images)

- Semantic Gap
	- Humans can differentiate cat and dog easily, but computers see the images as a big matrix of numbers. The difference between how human and computer sees an image is known as semantic gap.

- Possible Challenges
	- viewpoint variation - no matter how an object 'A' is rotated, it is still object 'A'
	- scale variation - tall, grande, venti coffee mug, still a coffee mug!
	- deformation - Recall the Gumby characters 
	- occlusions (part of object hidden) - picture of dog versus picture of dog under a blanket
	- illumination - an object subjet to different lighting conditions
	- background clutter - Where's Wally?
	- intra-class variation - all the different chairs, are still considered chairs
	- The classifier must handle the combination of the challenges aforementioned.
	- The success of an image classification job depends on the scope.
		- Too broad a scope (try to classify everything) can cause the project to fail easily.
		- A narrower/ more well-defined scope make the projects easier to manage.

- Types of Learning
	- Supervised
	- Unsupervised
	- Semi-supevised - only a subset of training data is labelled; we try to label the rest of the unlabelled data and utilize them as additional training data; need to tolerate a degree of inaccuracy
	
- Deep Learning Pipeline
	- Instead of writing a gazillion of if/else statements to differentiate images, we let the algorithms learn on their own.
	- Step 1 - Gather images and their labels (a finite set of categories)
				- Try to ensure each category is uniformly well-represented (i.e. each category has more or less same samples)	
				- If a category is overly represented - could lead to overfitting on that category.
				- There may be a need to deal with class imbalances.
	- Step 2 - Split dataset (Train / Test)
				- How about the hyperparameters? Set them using a validation set (which comes from training data and is a fake test set)
	- Step 3 - Train the network
	- Step 4 - Evaluate the network

- Traditional ML techniques on image classification involve feature extraction (raw pixels -> vector of numbers used for training). There is no need of feature extraction for a CNN.

- There is a chance that trained NN performs well on test set does not perform well on new unseen data. This is a matter of generalization and will be discussed further.
		